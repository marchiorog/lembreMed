import React, { useState, useRef } from 'react';
import {
  View,
  Text,
  TextInput,
  TouchableOpacity,
  FlatList,
  KeyboardAvoidingView,
  Platform,
  Alert,
} from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system/legacy';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { useGeminiChat } from '@services/chatGemini';
import { MessageText } from '@components/MessageText';
import styles from './styles';

interface Message {
  id: string;
  text: string;
  isUser: boolean;
  timestamp: Date;
  isAudio?: boolean;
  audioUri?: string;
}

// üîë Inst√¢ncia do Gemini direto aqui no Chat.tsx
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');

// üîä Transcri√ß√£o REAL usando Gemini (√°udio -> texto)
const transcreverAudio = async (uri: string): Promise<string> => {
  try {
    console.log('üìÅ URI do √°udio para transcri√ß√£o:', uri);

    // L√™ o arquivo de √°udio como base64
    const base64 = await FileSystem.readAsStringAsync(uri, {
      encoding: 'base64',
    });

    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

    const prompt = `
      Transcreva exatamente o conte√∫do deste √°udio em portugu√™s do Brasil.
      Retorne APENAS o texto falado, sem explica√ß√µes extras.
    `;

    const result = await model.generateContent([
      { text: prompt },
      {
        inlineData: {
          mimeType: 'audio/mp4', // m4a geralmente √© tratado como audio/mp4
          data: base64,
        },
      },
    ]);

    const texto = result.response.text().trim();
    console.log('üìù Texto transcrito (Gemini):', texto);
    return texto;
  } catch (error) {
    console.error('‚ùå Erro na transcri√ß√£o de √°udio (Gemini):', error);
    return '';
  }
};

const Chat = () => {
  const [messages, setMessages] = useState<Message[]>([
    {
      id: '1',
      text: 'Ol√°! Sou seu assistente m√©dico virtual. Como posso ajud√°-lo hoje?',
      isUser: false,
      timestamp: new Date(),
    },
  ]);
  const [inputText, setInputText] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const recordingRef = useRef<Audio.Recording | null>(null);
  const { gerarRespostaInteligente, loading } = useGeminiChat();

  const startRecording = async () => {
    try {
      if (isRecording) {
        console.log('‚ö† J√° est√° gravando.');
        return;
      }

      console.log('üîä Pedindo permiss√£o de microfone...');
      const permission = await Audio.requestPermissionsAsync();

      if (permission.status !== 'granted') {
        Alert.alert(
          'Permiss√£o negada',
          'Precisamos de permiss√£o para gravar √°udio.'
        );
        return;
      }

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      console.log('‚è∫ Iniciando grava√ß√£o...');
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );

      setRecording(recording);
      recordingRef.current = recording;
      setIsRecording(true);
      console.log('‚úÖ Grava√ß√£o iniciada!');
    } catch (error) {
      Alert.alert('Erro', 'N√£o foi poss√≠vel iniciar a grava√ß√£o.');
      console.error('‚ùå Erro ao iniciar grava√ß√£o:', error);
    }
  };

  const stopRecording = async () => {
    const activeRecording = recordingRef.current;

    if (!activeRecording) {
      console.log('‚ö† Nenhuma grava√ß√£o ativa para parar.');
      return;
    }

    try {
      console.log('‚èπ Parando grava√ß√£o...');
      setIsRecording(false);

      await activeRecording.stopAndUnloadAsync();
      const uri = activeRecording.getURI();
      console.log('üìÅ √Åudio salvo em:', uri);

      if (uri) {
        // 1) Transcrever o √°udio com Gemini
        let textoTranscrito = '';
        try {
          textoTranscrito = await transcreverAudio(uri);
        } catch (err) {
          console.error('‚ùå Erro na transcri√ß√£o:', err);
          textoTranscrito = '';
        }

        console.log('üìù Texto transcrito:', textoTranscrito);

        // 2) Criar mensagem do usu√°rio (texto vindo do √°udio)
        const userText =
          textoTranscrito || 'üé§ Mensagem de √°udio (n√£o foi poss√≠vel transcrever)';

        const audioMessage: Message = {
          id: Date.now().toString(),
          text: userText,
          isUser: true,
          timestamp: new Date(),
          isAudio: true,
          audioUri: uri,
        };

        setMessages(prev => [...prev, audioMessage]);

        // 3) Enviar texto transcrito para a IA
        try {
          const perguntaParaIA = textoTranscrito || '√°udio do usu√°rio';
          const respostaIA = await gerarRespostaInteligente(perguntaParaIA);

          const botResponse: Message = {
            id: (Date.now() + 1).toString(),
            text: respostaIA,
            isUser: false,
            timestamp: new Date(),
          };

          setMessages(prev => [...prev, botResponse]);
        } catch (error) {
          console.error('Erro IA:', error);
          const errorResponse: Message = {
            id: (Date.now() + 1).toString(),
            text: 'Desculpe, ocorreu um erro ao processar sua mensagem de √°udio. Tente novamente.',
            isUser: false,
            timestamp: new Date(),
          };
          setMessages(prev => [...prev, errorResponse]);
        }
      }
    } catch (error) {
      Alert.alert('Erro', 'N√£o foi poss√≠vel parar a grava√ß√£o.');
      console.error('‚ùå Erro ao parar grava√ß√£o:', error);
    } finally {
      setRecording(null);
      recordingRef.current = null;
    }
  };

  const playAudio = async (uri: string) => {
    try {
      const { sound } = await Audio.Sound.createAsync({ uri });
      await sound.playAsync();
    } catch (error) {
      Alert.alert('Erro', 'N√£o foi poss√≠vel reproduzir o √°udio.');
      console.error('‚ùå Erro ao reproduzir √°udio:', error);
    }
  };

  const sendMessage = async () => {
    const text = inputText.trim();
    if (!text) return;

    const newMessage: Message = {
      id: Date.now().toString(),
      text,
      isUser: true,
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, newMessage]);
    setInputText('');

    try {
      const respostaIA = await gerarRespostaInteligente(text);
      const botResponse: Message = {
        id: (Date.now() + 1).toString(),
        text: respostaIA,
        isUser: false,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, botResponse]);
    } catch (error) {
      console.error('Erro IA (texto):', error);
      const errorResponse: Message = {
        id: (Date.now() + 1).toString(),
        text: 'Desculpe, ocorreu um erro ao processar sua mensagem. Tente novamente.',
        isUser: false,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorResponse]);
    }
  };

  const renderMessage = ({ item }: { item: Message }) => (
    <View
      style={[
        styles.messageContainer,
        item.isUser ? styles.userMessage : styles.botMessage,
      ]}
    >
      {item.isAudio ? (
        // üîä Mensagem de √°udio clic√°vel + √≠cone
        <TouchableOpacity
          onPress={() => item.audioUri && playAudio(item.audioUri)}
        >
          <Text
            style={[
              styles.messageText,
              item.isUser ? styles.userMessageText : styles.botMessageText,
            ]}
          >
            ‚ñ∂Ô∏è {item.text}
          </Text>
        </TouchableOpacity>
      ) : (
        // üß† Mensagem de texto usando o componente do seu amigo
        <MessageText
          message={item.text}
          isUser={item.isUser}
          userTextStyle={[styles.messageText, styles.userMessageText]}
        />
      )}

      <Text style={styles.timestamp}>
        {item.timestamp.toLocaleTimeString('pt-BR', {
          hour: '2-digit',
          minute: '2-digit',
        })}
      </Text>
    </View>
  );

  return (
    <View style={styles.outerContainer}>
      <KeyboardAvoidingView
        style={styles.container}
        behavior={Platform.OS === 'ios' ? 'padding' : 'height'}
      >
        <Text style={styles.title}>Chat de Suporte</Text>

        <FlatList
          data={messages}
          renderItem={renderMessage}
          keyExtractor={item => item.id}
          style={styles.messagesList}
          contentContainerStyle={styles.messagesContent}
          showsVerticalScrollIndicator={false}
          ListFooterComponent={() =>
            loading ? (
              <View style={styles.loadingContainer}>
                <Text style={styles.loadingText}>
                  Assistente est√° digitando...
                </Text>
              </View>
            ) : null
          }
        />

        <View style={styles.inputContainer}>
          <TextInput
            style={styles.textInput}
            value={inputText}
            onChangeText={setInputText}
            placeholder="Digite sua mensagem..."
            placeholderTextColor="#999"
            multiline
            maxLength={500}
          />

          <TouchableOpacity
            style={[
              styles.audioButton,
              isRecording && styles.audioButtonRecording,
            ]}
            onPress={isRecording ? stopRecording : startRecording}
          >
            <Ionicons
              name={isRecording ? 'stop' : 'mic'}
              size={20}
              color={isRecording ? '#fff' : '#70C4E8'}
            />
          </TouchableOpacity>

          <TouchableOpacity
            style={styles.sendButton}
            onPress={sendMessage}
            disabled={!inputText.trim()}
          >
            <Ionicons
              name="send"
              size={20}
              color={inputText.trim() ? '#fff' : '#ccc'}
            />
          </TouchableOpacity>
        </View>
      </KeyboardAvoidingView>
    </View>
  );
};

export default Chat;
